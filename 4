'''
transforms.Compose([
    #将给定的PIL.Image进行中心切割，得到给定的size，
    #可以是元组，(target_height,target_width)
    #也可以是整型，在这种情况下，切出来图形是正方形
    transforms.CenterCrop(10),
    #随机选取切割中心点的位置
    transforms,RandomCrop(20,padding=0),
    #把一个取值范围是[0,255]的PIL.image或者形状为(H,W,C)的
    #numpy.ndarray,转换成形状为(C,H,W)取值范围是[0,1]的torch.FloatTensor
    transforms.ToTensor(),
    #规范化到[-1,1]
    transforms.Normalize(mean=(0.5,0.5,0.5),std=(0.5,0.5,0.5))
])
'''
'''
#实例化SummaryWriter类，指明记录日志路径等信息
from torch.utils.tensorboard import SummaryWriter
#如果当前目录没有logs，则自动创建
writer=SummaryWriter(log_dir='logs')
#调用实例
writer.add_xxx()
#关闭writer
writer.close()
SummaryWriter格式
SummaryWriter(lag_dir=None,comment='',**kwargs)
#comment表示在文件命名加上comment后缀
#调用相应接口
add_xxx(tag-name,object,iteration-number)
#启动TensorBoard
tensorboardv --loadir=logs --port 6006
'''
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.tensorboard import SummaryWriter

# 构建神经网络
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)
        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)
        self.conv2_drop = nn.Dropout2d()
        self.fc1 = nn.Linear(320, 50)
        self.fc2 = nn.Linear(50, 10)
        self.bn = nn.BatchNorm2d(20)

    def forward(self, x):
        x = F.max_pool2d(F.relu(self.conv1(x)), 2)
        x = F.max_pool2d(F.relu(self.conv2_drop(self.conv2(x))), 2)
        x = self.bn(x)
        x = x.view(-1, 320)  # 展平
        x = F.relu(self.fc1(x))
        x = F.dropout(x, training=self.training)  # 使用 Dropout正则化
        x = self.fc2(x)
        return x  # 返回 logits，而不是 softmax 输出

# 创建输入张量
input_tensor = torch.rand(32, 1, 28, 28)

# 实例化神经网络
model = Net()

# 创建 SummaryWriter 实例
writer = SummaryWriter('logs')

# 模拟一个训练步骤并计算损失
# 假设我们有一些随机生成的目标标签
targets = torch.randint(0, 10, (32,))
# 前向传播
outputs = model(input_tensor)
# 计算损失
criterion = nn.CrossEntropyLoss()
loss_value = criterion(outputs, targets)

# 写入数据
step = 0  # 指定步数
writer.add_scalar('loss', loss_value.item(), step)

# 将模型保存为图像
writer.add_graph(model, (input_tensor,))

# 关闭 writer
writer.close()

# 检查日志目录中是否存在事件文件
import os
log_dir = 'logs'
if os.path.exists(log_dir) and os.listdir(log_dir):
    print(f"事件文件已写入到 {log_dir}")
else:
    print(f"事件文件未写入到 {log_dir}，检查代码逻辑")
    '''
#构建网络层，添加两个dropout
net1_overfitting=torch.nn.Sequential(
    torch.nn.Linear(13,16),
    torch.nn.ReLU(),
    torch.nn.Linear(16,32),
    torch.nn.ReLU(),
    torch.nn.Linear(32,1)
)
net1_dropped=torch.nn.Sequential(
    torch.nn.Linear(13,16),
    torch.nn.Dropout(0.5),
    torch.nn.ReLU(),
    torch.nn.Linear(16,32),
    torch.nn.Dropout(0.5),
    torch.nn.ReLU(),
    torch.nn.Linear(32,1) 
)
writer.add_scalars('test_group_loss',{'origloss':orig_loss.item(),'droploss':drop_loss.item()},epoch)
'''
